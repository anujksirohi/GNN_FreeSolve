{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys, os\n",
    "import time\n",
    "import warnings\n",
    "import torch\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "from torch.serialization import save\n",
    "from gnn.model.metric import EarlyStopping\n",
    "from gnn.model.gated_solv_network import CrossAttention\n",
    "from gnn.data.dataset import SolvationDataset, train_validation_test_split, load_mols_labels\n",
    "from gnn.data.dataloader import DataLoaderSolvation\n",
    "from gnn.data.grapher import HeteroMoleculeGraph\n",
    "from gnn.data.featurizer import (SolventAtomFeaturizer, BondAsNodeFeaturizerFull, SolventGlobalFeaturizer)\n",
    "from gnn.utils import (load_checkpoints,save_checkpoints,seed_torch, pickle_dump, yaml_dump)\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_seed=2\n",
    "\n",
    "dataset_file =\"./input_data/FreeSolv.csv\"\n",
    "save_dir = \"./outputnew\"\n",
    "output_file = \"results.pkl\"\n",
    "dielectric_constants=None\n",
    "molecular_volume = False\n",
    "molecular_refractivity = False\n",
    "dataset_state_dict_filename = None\n",
    "\n",
    "\n",
    "feature_scaling= True\n",
    "solvent_split = None\n",
    "element_split = None\n",
    "scaffold_split = False\n",
    "attention_map = False\n",
    "distributed = 0\n",
    "restore=0\n",
    "batch_size = 100\n",
    "attention_map = False\n",
    "embedding_size =24\n",
    "\n",
    "# gated layer\n",
    "gated_num_layers =3\n",
    "gated_hidden_size =[192, 192, 192]\n",
    "gated_num_fc_layers =2\n",
    "gated_graph_norm =1\n",
    "gated_batch_norm = 1\n",
    "gated_activation= \"LeakyReLU\"\n",
    "gated_residual =1\n",
    "gated_dropout = 0.4\n",
    "\n",
    "# readout layer\n",
    "num_lstm_iters =6 #,help=\"number of iterations for the LSTM in set2set readout layer\")\n",
    "num_lstm_layers=3 # help=\"number of layers for the LSTM in set2set readout layer\")\n",
    "\n",
    "# fc layer\n",
    "fc_num_layers =2\n",
    "fc_hidden_size = [64, 32]\n",
    "fc_batch_norm =0\n",
    "fc_activation = \"LeakyReLU\"\n",
    "fc_dropout = 0.2\n",
    "\n",
    "start_epoch=0\n",
    "epochs = 1000\n",
    "lr = 0.001\n",
    "weight_decay =0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grapher(dielectric_constant=None, mol_volume=False, mol_refract=False):\n",
    "    atom_featurizer  = SolventAtomFeaturizer()\n",
    "    bond_featurizer  = BondAsNodeFeaturizerFull(length_featurizer=None, dative=False)\n",
    "    global_featurizer= SolventGlobalFeaturizer(dielectric_constant=dielectric_constant, mol_volume=mol_volume, mol_refract=mol_refract)\n",
    "\n",
    "    grapher = HeteroMoleculeGraph(atom_featurizer, bond_featurizer, global_featurizer, self_loop=True)\n",
    "\n",
    "    return grapher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_torch(random_seed)\n",
    "\n",
    "mols, labels = load_mols_labels(dataset_file)\n",
    "dataset = SolvationDataset(solute_grapher = grapher(mol_volume=molecular_volume, mol_refract = molecular_refractivity),\n",
    "                           solvent_grapher = grapher(mol_volume=molecular_volume, mol_refract = molecular_refractivity),\n",
    "            molecules = mols, labels = labels, solute_extra_features = None, solvent_extra_features = None, feature_transformer = False,\n",
    "            label_transformer= False, state_dict_filename=dataset_state_dict_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the solute and solvent graphers for loading datasets later\n",
    "pickle_dump([dataset.solute_grapher, dataset.solvent_grapher], os.path.join(save_dir,\"graphers.pkl\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset SolvationDataset\n",
       "Length: 642\n",
       "Solvent feature: atom, size: 28\n",
       "Solvent feature: bond, size: 11\n",
       "Solvent feature: global, size: 3\n",
       "Solute feature: atom, size: 28\n",
       "Solute feature: bond, size: 11\n",
       "Solute feature: global, size: 3\n",
       "Solute feature: atom, name: ['total degree', 'partial/formal charge', 'is aromatic', 'is in ring', 'num lone pairs', 'num total H', 'H bond acceptor', 'H bond donor', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'hybridization', 'hybridization', 'hybridization', 'hybridization', 'ring size', 'ring size', 'ring size', 'ring size', 'ring size']\n",
       "Solute feature: bond, name: ['in_ring', 'conjugated', 'ring size', 'ring size', 'ring size', 'ring size', 'ring size', 'single', 'double', 'triple', 'aromatic']\n",
       "Solute feature: global, name: ['num atoms', 'num bonds', 'molecule weight']\n",
       "Solvent feature: atom, name: ['total degree', 'partial/formal charge', 'is aromatic', 'is in ring', 'num lone pairs', 'num total H', 'H bond acceptor', 'H bond donor', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'hybridization', 'hybridization', 'hybridization', 'hybridization', 'ring size', 'ring size', 'ring size', 'ring size', 'ring size']\n",
       "Solvent feature: bond, name: ['in_ring', 'conjugated', 'ring size', 'ring size', 'ring size', 'ring size', 'ring size', 'single', 'double', 'triple', 'aromatic']\n",
       "Solvent feature: global, name: ['num atoms', 'num bonds', 'molecule weight']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data using random seed 2\n"
     ]
    }
   ],
   "source": [
    "best = np.finfo(np.float32).max\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "if (solvent_split is None) and (element_split is None) and (scaffold_split is False):\n",
    "    print(f'Splitting data using random seed {random_seed}')\n",
    "    trainset, valset, testset = train_validation_test_split(dataset, validation=0.1, test=0.1, random_seed=random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standard deviation for feature 1 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 2 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 3 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 6 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 7 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 8 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 9 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 10 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 11 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 13 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 14 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 16 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 17 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 18 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 19 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 21 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 22 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 23 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 24 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 25 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 26 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 27 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 0 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 1 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 2 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 3 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 4 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 5 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 6 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 7 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 8 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 9 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 10 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 0 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 1 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 2 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 21 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 22 is 0.0, smaller than 0.001. You may want to exclude this feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset size: 514, valset size: 64: testset size: 64.\n"
     ]
    }
   ],
   "source": [
    "# Scale training dataset features\n",
    "if feature_scaling:\n",
    "    solute_features_scaler, solvent_features_scaler = trainset.normalize_features()\n",
    "    valset.normalize_features(solute_features_scaler, solvent_features_scaler)\n",
    "    testset.normalize_features(solute_features_scaler, solvent_features_scaler)\n",
    "else:\n",
    "    solute_features_scaler, solvent_features_scaler = None, None\n",
    "label_scaler = trainset.normalize_labels()\n",
    "\n",
    "#if not distributed or (distributed and gpu == 0):\n",
    "torch.save(dataset.state_dict(), \"./output/dataset_state_dict.pkl\")\n",
    "print( \"Trainset size: {}, valset size: {}: testset size: {}.\".format(len(trainset), len(valset), len(testset)))\n",
    "#if distributed:\n",
    "#    train_sampler = torch.utils.data.distributed.DistributedSampler(trainset)\n",
    "#else:\n",
    "train_sampler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoaderSolvation(trainset, batch_size = batch_size, shuffle = (train_sampler is None), sampler = train_sampler)\n",
    "bs = max(len(valset) // 10, 1)\n",
    "val_loader = DataLoaderSolvation(valset, batch_size=bs, shuffle=False)\n",
    "bs = max(len(testset) // 10, 1)\n",
    "test_loader = DataLoaderSolvation(testset, batch_size=bs, shuffle=False)\n",
    "### model\n",
    "feature_names = [\"atom\", \"bond\", \"global\"]\n",
    "set2set_ntypes_direct = [\"global\"]\n",
    "solute_feature_size = dataset.feature_sizes[0]\n",
    "solvent_feature_size = dataset.feature_sizes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross interaction map\n"
     ]
    }
   ],
   "source": [
    "model =  CrossAttention(solute_in_feats=solute_feature_size, solvent_in_feats=solvent_feature_size,\n",
    "        embedding_size=embedding_size,gated_num_layers=gated_num_layers, gated_hidden_size=gated_hidden_size,\n",
    "        gated_num_fc_layers=gated_num_fc_layers,gated_graph_norm=gated_graph_norm,gated_batch_norm=gated_batch_norm,\n",
    "        gated_activation=gated_activation, gated_residual=gated_residual, gated_dropout=gated_dropout,num_lstm_iters=num_lstm_iters,\n",
    "        num_lstm_layers=num_lstm_layers, set2set_ntypes_direct=set2set_ntypes_direct,fc_num_layers=fc_num_layers,\n",
    "        fc_hidden_size=fc_hidden_size, fc_batch_norm=fc_batch_norm, fc_activation=fc_activation, fc_dropout=fc_dropout, outdim=1, conv=\"GatedGCNConv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam( model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "loss_func = MSELoss(reduction=\"mean\")\n",
    "metric = L1Loss(reduction=\"sum\")\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.4, patience=50, verbose=True)\n",
    "stopper = EarlyStopping(patience=150)\n",
    "state_dict_objs = {\"model\": model, \"optimizer\": optimizer, \"scheduler\": scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer, model, nodes, data_loader, loss_fn, metric_fn):\n",
    "    import torch\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    count = 0.0\n",
    "\n",
    "    for it, (solute_batched_graph, solvent_batched_graph, label) in enumerate(data_loader):\n",
    "        solute_feats = {nt: solute_batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "        solvent_feats = {nt: solvent_batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "        target = torch.squeeze(label[\"value\"])\n",
    "        solute_norm_atom = label[\"solute_norm_atom\"]\n",
    "        solute_norm_bond = label[\"solute_norm_bond\"]\n",
    "        solvent_norm_atom = label[\"solvent_norm_atom\"]\n",
    "        solvent_norm_bond = label[\"solvent_norm_bond\"]\n",
    "        #stdev = label[\"scaler_stdev\"]\n",
    "\n",
    "        if device is not None:\n",
    "            solute_feats = {k: v.to(device) for k, v in solute_feats.items()}\n",
    "            solvent_feats = {k: v.to(device) for k, v in solvent_feats.items()}\n",
    "            target = target.to(device)\n",
    "            solute_norm_atom = solute_norm_atom #.to(device)\n",
    "            solute_norm_bond = solute_norm_bond #.to(device)\n",
    "            solvent_norm_atom = solvent_norm_atom #.to(device)\n",
    "            solvent_norm_bond = solvent_norm_bond #.to(device)\n",
    "            #stdev = stdev.to(device)\n",
    "        \n",
    "        pred = model(solute_batched_graph, solvent_batched_graph, solute_feats, solvent_feats, solute_norm_atom, solute_norm_bond, \n",
    "                     solvent_norm_atom, solvent_norm_bond)\n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "\n",
    "        loss = loss_fn(pred, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.detach().item()\n",
    "        accuracy += metric_fn(pred, target).detach().item()\n",
    "        count += len(target)\n",
    "    \n",
    "    epoch_loss /= it + 1\n",
    "    accuracy /= count\n",
    "\n",
    "    return epoch_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, nodes, data_loader, metric_fn, scaler = None, return_preds=False):\n",
    "    import torch\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        accuracy = 0.0\n",
    "        count = 0.0\n",
    "\n",
    "        preds = []\n",
    "        y_true = []\n",
    "\n",
    "        for solute_batched_graph, solvent_batched_graph, label in data_loader:\n",
    "            solute_feats = {nt: solute_batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "            solvent_feats = {nt: solvent_batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "            target = torch.squeeze(label[\"value\"])\n",
    "            #stdev = label[\"scaler_stdev\"]\n",
    "            solvent_norm_atom = label[\"solvent_norm_atom\"]\n",
    "            solvent_norm_bond = label[\"solvent_norm_bond\"]\n",
    "            solute_norm_atom = label[\"solute_norm_atom\"]\n",
    "            solute_norm_bond = label[\"solute_norm_bond\"]\n",
    "            \n",
    "            if device is not None:\n",
    "                solute_feats = {k: v.to(device) for k, v in solute_feats.items()}\n",
    "                solvent_feats = {k: v.to(device) for k, v in solvent_feats.items()}\n",
    "                target = target.to(device)\n",
    "                solute_norm_atom = solute_norm_atom.to(device)\n",
    "                solute_norm_bond = solute_norm_bond.to(device)\n",
    "                solvent_norm_atom = solvent_norm_atom.to(device)\n",
    "                solvent_norm_bond = solvent_norm_bond.to(device)\n",
    "                #stdev = stdev.to(device)\n",
    "\n",
    "            pred = model(solute_batched_graph, solvent_batched_graph, solute_feats, \n",
    "                     solvent_feats, solute_norm_atom, solute_norm_bond, \n",
    "                     solvent_norm_atom, solvent_norm_bond)\n",
    "            pred = pred.view(-1)\n",
    "            target = target.view(-1)\n",
    "\n",
    "            # Inverse scale \n",
    "            if scaler is not None:\n",
    "                pred = scaler.inverse_transform(pred.cpu())\n",
    "                pred = pred.to(device)\n",
    "\n",
    "            accuracy += metric_fn(pred, target).detach().item()\n",
    "            count += len(target)\n",
    "            \n",
    "            batch_pred = pred.tolist()\n",
    "            batch_target = target.tolist()\n",
    "            preds.extend(batch_pred)\n",
    "            y_true.extend(batch_target)\n",
    "\n",
    "    if return_preds:\n",
    "        return y_true, preds\n",
    "\n",
    "    else:\n",
    "        return accuracy / count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   MSE Loss       Train MAE      Val MAE        Time (s)\n",
      "    0   1.232183e+00   7.850856e-01   2.512466e+00   18.36\n",
      "    1   9.359962e-01   7.269607e-01   2.439717e+00   15.99\n",
      "    2   7.265916e-01   6.413350e-01   2.333654e+00   15.67\n",
      "    3   6.031480e-01   6.020138e-01   2.174176e+00   15.39\n",
      "    4   4.287728e-01   4.902507e-01   1.615106e+00   13.57\n",
      "    5   4.718710e-01   4.963723e-01   1.933856e+00   13.30\n",
      "    6   3.546169e-01   4.421367e-01   1.471781e+00   13.42\n",
      "    7   3.176426e-01   4.287195e-01   1.318893e+00   13.69\n",
      "    8   3.033718e-01   4.154650e-01   1.208500e+00   13.63\n",
      "    9   3.263239e-01   3.721361e-01   1.399044e+00   13.78\n",
      "   10   2.616111e-01   3.825664e-01   1.112234e+00   13.97\n",
      "   11   2.553513e-01   3.836095e-01   1.352343e+00   14.60\n",
      "   12   2.901275e-01   3.904938e-01   1.026652e+00   13.81\n",
      "   13   2.465743e-01   3.777791e-01   1.115096e+00   13.48\n",
      "   14   2.085585e-01   3.424566e-01   1.083888e+00   13.86\n",
      "   15   2.551448e-01   3.576358e-01   1.158770e+00   13.12\n",
      "   16   2.650302e-01   3.672855e-01   1.061542e+00   13.30\n",
      "   17   2.591244e-01   3.420260e-01   1.198677e+00   13.44\n",
      "   18   2.284222e-01   3.229786e-01   9.454654e-01   13.60\n",
      "   19   2.153789e-01   3.672384e-01   9.679937e-01   13.58\n",
      "   20   2.942964e-01   3.553300e-01   1.026667e+00   13.84\n",
      "   21   2.370435e-01   3.439532e-01   1.054416e+00   13.62\n",
      "   22   1.939136e-01   3.273001e-01   9.549985e-01   13.95\n",
      "   23   1.860150e-01   3.124442e-01   9.248281e-01   13.34\n",
      "   24   1.841736e-01   3.095935e-01   9.456949e-01   13.06\n",
      "   25   2.174798e-01   3.302161e-01   8.960947e-01   13.30\n",
      "   26   2.197244e-01   3.423701e-01   9.142439e-01   13.20\n",
      "   27   2.231525e-01   3.509380e-01   9.507668e-01   13.65\n",
      "   28   1.830158e-01   3.165794e-01   9.194262e-01   13.35\n",
      "   29   1.748962e-01   3.074486e-01   9.073202e-01   13.71\n",
      "   30   1.627737e-01   3.008475e-01   9.670243e-01   12.95\n",
      "   31   1.676191e-01   2.984450e-01   8.708263e-01   14.51\n",
      "   32   2.119173e-01   3.192257e-01   9.016748e-01   14.63\n",
      "   33   1.645404e-01   3.035046e-01   9.307654e-01   14.78\n",
      "   34   1.694912e-01   3.113152e-01   8.952691e-01   13.44\n",
      "   35   1.958097e-01   3.077277e-01   8.719705e-01   13.30\n",
      "   36   1.491418e-01   2.843438e-01   8.782504e-01   13.35\n",
      "   37   1.569179e-01   3.000744e-01   1.065186e+00   13.06\n",
      "   38   1.663499e-01   2.909405e-01   9.544787e-01   13.26\n",
      "   39   1.329838e-01   2.811449e-01   8.857648e-01   13.69\n",
      "   40   1.649824e-01   2.983542e-01   1.056036e+00   13.38\n",
      "   41   1.908869e-01   2.862597e-01   8.687194e-01   13.22\n",
      "   42   1.388904e-01   2.711871e-01   9.652281e-01   13.11\n",
      "   43   1.175300e-01   2.633960e-01   8.988800e-01   13.39\n",
      "   44   1.620564e-01   2.767041e-01   9.217597e-01   13.53\n",
      "   45   1.725113e-01   2.944595e-01   7.973432e-01   13.70\n",
      "   46   1.435869e-01   2.729749e-01   8.877982e-01   13.63\n",
      "   47   1.550325e-01   2.627497e-01   9.260054e-01   13.56\n",
      "   48   1.752355e-01   2.731271e-01   7.467366e-01   13.22\n",
      "   49   1.658597e-01   3.005552e-01   8.475036e-01   13.28\n",
      "   50   1.703313e-01   2.688886e-01   9.451254e-01   13.04\n",
      "   51   1.545708e-01   2.892781e-01   8.571666e-01   13.45\n",
      "   52   1.826309e-01   2.902041e-01   7.809006e-01   13.40\n",
      "   53   1.516640e-01   2.742665e-01   9.276730e-01   13.03\n",
      "   54   1.414583e-01   2.648056e-01   8.833407e-01   13.35\n",
      "   55   1.371953e-01   2.634057e-01   8.609574e-01   13.17\n",
      "   56   1.268703e-01   2.674062e-01   1.085678e+00   13.86\n",
      "   57   1.318456e-01   2.619588e-01   9.507335e-01   13.85\n",
      "   58   1.705145e-01   2.702118e-01   8.110892e-01   13.59\n",
      "   59   1.156382e-01   2.649755e-01   8.904897e-01   13.12\n",
      "   60   1.502682e-01   2.702765e-01   7.857542e-01   13.25\n",
      "   61   1.118332e-01   2.456833e-01   8.980425e-01   13.16\n",
      "   62   1.338693e-01   2.591174e-01   9.385345e-01   13.13\n",
      "   63   1.504402e-01   2.673067e-01   7.355987e-01   13.73\n",
      "   64   1.448029e-01   2.693133e-01   8.892498e-01   13.42\n",
      "   65   1.429656e-01   2.707716e-01   8.816017e-01   13.50\n",
      "   66   1.124575e-01   2.620418e-01   9.735418e-01   13.32\n",
      "   67   1.260656e-01   2.492683e-01   7.514459e-01   13.16\n",
      "   68   1.514311e-01   2.635250e-01   8.839442e-01   13.77\n",
      "   69   1.407913e-01   2.695711e-01   9.950492e-01   13.61\n",
      "   70   1.354006e-01   2.658087e-01   8.451014e-01   13.05\n",
      "   71   1.465144e-01   2.584316e-01   1.123529e+00   13.14\n",
      "   72   1.216735e-01   2.594238e-01   8.316319e-01   13.26\n",
      "   73   1.464813e-01   2.444149e-01   8.789190e-01   13.29\n",
      "   74   1.511778e-01   2.756858e-01   8.608512e-01   13.18\n",
      "   75   1.574976e-01   2.581897e-01   1.274495e+00   13.42\n",
      "   76   1.191528e-01   2.486444e-01   7.151419e-01   13.17\n",
      "   77   1.987359e-01   2.576341e-01   9.646481e-01   13.34\n",
      "   78   1.588444e-01   2.934296e-01   8.923911e-01   13.03\n",
      "   79   1.275116e-01   2.324318e-01   8.683839e-01   14.69\n",
      "   80   1.537735e-01   2.570145e-01   8.828986e-01   13.32\n",
      "   81   1.528447e-01   2.614989e-01   1.018187e+00   13.46\n",
      "   82   1.210846e-01   2.614245e-01   9.072863e-01   13.29\n",
      "   83   1.062675e-01   2.522300e-01   9.074349e-01   13.80\n",
      "   84   1.008242e-01   2.423989e-01   7.937683e-01   13.28\n",
      "   85   1.240187e-01   2.566184e-01   8.964351e-01   13.31\n",
      "   86   9.633619e-02   2.379022e-01   8.620984e-01   13.30\n",
      "   87   9.638636e-02   2.429010e-01   9.118815e-01   13.52\n",
      "   88   1.671614e-01   2.607964e-01   8.492350e-01   13.12\n",
      "   89   1.499434e-01   2.541383e-01   1.015182e+00   13.06\n",
      "   90   1.708907e-01   2.538769e-01   7.938587e-01   13.55\n",
      "   91   1.298183e-01   2.645809e-01   7.979912e-01   13.19\n",
      "   92   1.236160e-01   2.562096e-01   9.112628e-01   13.66\n",
      "   93   1.554204e-01   2.476819e-01   9.126994e-01   13.06\n",
      "   94   1.741155e-01   2.681774e-01   6.543951e-01   13.47\n",
      "   95   1.151119e-01   2.370997e-01   7.842324e-01   13.07\n",
      "   96   1.154210e-01   2.357873e-01   9.771911e-01   13.22\n",
      "   97   1.118106e-01   2.451427e-01   8.127151e-01   13.36\n",
      "   98   1.402986e-01   2.522737e-01   8.317186e-01   13.87\n",
      "   99   1.052502e-01   2.352693e-01   7.986302e-01   14.40\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, 100):\n",
    "    ti = time.time()\n",
    "    loss, train_acc = train(optimizer, model, feature_names, train_loader, loss_func, metric)\n",
    "\n",
    "    if np.isnan(loss):\n",
    "        print(\"\\n\\nBad, we get nan for loss. Exiting\")\n",
    "        sys.stdout.flush()\n",
    "        sys.exit(1)\n",
    "    #evaluate\n",
    "    val_acc = evaluate(model, feature_names, val_loader, metric, label_scaler)\n",
    "    if stopper.step(val_acc):\n",
    "        pickle_dump(best, os.path.join(save_dir, output_file))  # save results for hyperparam tune\n",
    "        break\n",
    "    scheduler.step(val_acc)\n",
    "    is_best = val_acc < best\n",
    "    if is_best:\n",
    "        best = val_acc\n",
    "        #print(\"best\", best)\n",
    "    # save checkpoint\n",
    "    misc_objs = {\"best\": best, \"epoch\": epoch}\n",
    "    scaler_objs = {'label_scaler': {'means': label_scaler.mean, 'stds': label_scaler.std} if label_scaler is not None else None,\n",
    "                             'solute_features_scaler': {'means': solute_features_scaler.mean,'stds': solute_features_scaler.std} if solute_features_scaler is not None else None,\n",
    "                              'solvent_features_scaler': {'means': solvent_features_scaler.mean,'stds': solvent_features_scaler.std} if solvent_features_scaler is not None else None}\n",
    "    save_checkpoints(state_dict_objs, misc_objs,scaler_objs,is_best, msg=f\"epoch: {epoch}, score {val_acc}\", save_dir=save_dir)\n",
    "    tt = time.time() - ti\n",
    "    if epoch ==0: \n",
    "        print(\"{:5}   {:12}   {:12}   {:12}   {:5}\".format(\"Epoch\", \"MSE Loss\", \"Train MAE\", \"Val MAE\", \"Time (s)\"))\n",
    "    print(\"{:5d}   {:12.6e}   {:12.6e}   {:12.6e}   {:.2f}\".format(epoch, loss, train_acc, val_acc, tt))\n",
    "    if epoch % 10 == 0:\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#Test MAE: 8.393481e-01 \n",
      "\n",
      "\n",
      "#Test RMSE: 1.179982e+00 \n",
      "\n",
      "\n",
      "Finish training at: 2025-03-10 01:32:57.467913\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate(model, feature_names, test_loader, metric, label_scaler)\n",
    "y_true, y_pred = evaluate(model, feature_names, test_loader, metric, label_scaler, return_preds=True)\n",
    "print(\"\\n#Test MAE: {:12.6e} \\n\".format(test_acc))\n",
    "print(\"\\n#Test RMSE: {:12.6e} \\n\".format(mean_squared_error(y_true, y_pred, squared=False)))\n",
    "print(\"\\nFinish training at:\", datetime.now())\n",
    "results_dict = {'y_true': y_true, 'y_pred': y_pred}\n",
    "pickle_dump(results_dict, os.path.join(save_dir, f'seed_{random_seed}_test_results.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test best model saved during training and save the Test results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = load_checkpoints(state_dict_objs, save_dir, filename=\"best_checkpoint.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#Test MAE: 6.119657e-01 \n",
      "\n",
      "\n",
      "#Test RMSE: 8.546843e-01 \n",
      "\n",
      "\n",
      "Finish training at: 2025-03-10 01:37:52.723112\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate(model, feature_names, test_loader, metric, label_scaler)\n",
    "y_true, y_pred = evaluate(model, feature_names, test_loader, metric, label_scaler, return_preds=True)\n",
    "print(\"\\n#Test MAE: {:12.6e} \\n\".format(test_acc))\n",
    "print(\"\\n#Test RMSE: {:12.6e} \\n\".format(mean_squared_error(y_true, y_pred, squared=False)))\n",
    "print(\"\\nFinish training at:\", datetime.now())\n",
    "results_dict = {'y_true': y_true, 'y_pred': y_pred}\n",
    "pickle_dump(results_dict, os.path.join(save_dir, f'seed_{random_seed}_test_results.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(save_dir, f'seed_{random_seed}_test_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [-2.3399999141693115, -4.849999904632568, -1.4500000476837158, -2.440000057220459, 1.5800000429153442, -2.4000000953674316, -4.289999961853027, -8.149999618530273, -5.820000171661377, -3.680000066757202, -3.0399999618530273, -5.659999847412109, -0.23000000417232513, -10.210000038146973, -4.150000095367432, 1.6799999475479126, -4.119999885559082, -9.649999618530273, -3.809999942779541, 0.009999999776482582, -9.729999542236328, -3.130000114440918, -0.5, -5.03000020980835, -2.009999990463257, -2.809999942779541, -2.549999952316284, -16.43000030517578, 0.4000000059604645, -2.9200000762939453, -4.059999942779541, -2.2100000381469727, -2.259999990463257, -3.450000047683716, -4.090000152587891, -9.520000457763672, 1.2300000190734863, -8.260000228881836, -5.739999771118164, -5.900000095367432, -2.869999885559082, 0.07999999821186066, -0.8199999928474426, -4.429999828338623, -1.9500000476837158, 1.309999942779541, -1.590000033378601, -4.690000057220459, -0.9900000095367432, -0.44999998807907104, 1.659999966621399, -2.490000009536743, -1.9900000095367432, 2.930000066757202, -2.700000047683716, -4.909999847412109, -4.0, -2.930000066757202, 1.8300000429153442, 0.3400000035762787, -2.369999885559082, -9.609999656677246, -7.369999885559082, -2.3299999237060547]\n",
      "y_pred: [-1.9893331759515653, -4.995928579341303, -3.759700546817068, -3.1527523301108755, 1.7481984404018536, -2.5033539257403463, -3.7251219253262686, -6.4772337261507875, -6.390352361316042, -2.7311968320703475, -2.5919665200547817, -5.685612780925764, -0.2602375591761934, -8.77994314146315, -3.34941418816405, 1.6600000304822733, -4.130840645743195, -9.307441974789691, -3.3789312500452118, 0.06719583166972987, -9.225088350234959, -3.153751370216394, 1.7884306670957328, -5.040057251033795, -2.191042154915354, -2.4695569977346574, -2.817508663895434, -10.736379551443285, 1.4555197642413549, -3.076866181916446, -4.8548390932926555, -3.0494057801109324, -2.898251224306432, -5.048767381486558, -4.300243212441545, -8.810964303248337, 1.712530964204261, -7.172171728309031, -7.202121715427047, -6.335343157506911, -3.7596245226466976, 0.2528140887074932, -1.4640233672639682, -4.8947105882448, -2.132965817832767, 1.6844701482532174, -2.2124618765170174, -5.482004729972816, -1.130946507771014, -0.33631689127021547, 1.7447944434401523, -3.153476976001476, -1.555742226672887, 3.1114803648542595, -2.868851027487165, -6.40588250811915, -3.5766774838618094, -3.166873849223911, 1.897190727360703, 0.40108597298525117, -1.470922825925677, -9.015123971437461, -8.373044337334985, -2.5063185147839997]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "with open(file_path, 'rb') as file:\n",
    "    results_dict = pickle.load(file)\n",
    "\n",
    "# Access the values\n",
    "y_true = results_dict['y_true']\n",
    "y_pred = results_dict['y_pred']\n",
    "# Print or process the data\n",
    "print(\"y_true:\", y_true)\n",
    "print(\"y_pred:\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
